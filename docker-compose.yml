services:
    RALM:
      image: hyukkyukang/ralm:py3.13-cuda-12.8.1-cudnn-devel-ubuntu24.04
      container_name: RALM
  
      shm_size: 24gb
      ulimits:
        memlock: -1
      stdin_open: true
      tty: true
      user: root
      network_mode: "host"
  
      environment:
        - TZ=Asia/Seoul
        - UID=${UID}
        - GID=${GID}
  
      volumes:
        - /etc/timezone:/etc/timezone:ro
        - ./:/home/user/RALM
        - /mnt:/mnt
      working_dir: /home/user/RALM
  
      command: >
        bash -c "
          # 1) adjust UID / GID before any 'user' process starts
          groupmod -o -g ${GID} user &&
          usermod  -o -u ${UID} -g ${GID} user &&
          chown -R ${UID}:${GID} /home/user &&
          # 2) ensure user-site executables are on PATH
          echo \"export PATH=$HOME/.local/bin:$PATH\" >> /home/user/.bashrc &&
          # 3) drop privileges and stay alive
          su - user -c 'exec tail -f /dev/null'
        "
  
      deploy:
        resources:
          reservations:
            devices:
              - capabilities: [gpu]
  
